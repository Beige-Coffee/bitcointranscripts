---
title: Matt Corallo and Compact Blocks/FIBRE - Episode 6
transcript_by: Whisper AI & PyAnnote
categories: ['podcast']
tag: []
---

Chaincode Labs podcast: Matt Corallo and Compact Blocks/FIBRE - Episode 6

SPEAKER_02: If not, let's make this as screaming fast as possible, let's optimize who you connect to for the lowest latency, because once you start doing that, it becomes very hard to keep that riplessness property.

SPEAKER_03: Hi, everyone. Welcome to the Chaincode Podcast. I'm here with Jonas and John.

SPEAKER_00: Hi, Carly. Hey, Carly.

SPEAKER_03: Hey guys, who are we chatting with today?

SPEAKER_01: We're going to be talking to Matt Corallo, otherwise known as Blue Matt.

SPEAKER_00: I first met Matt back in 2016 when he ran the first ChainCode residency and I was a resident and It's what set me on my path to be a full-time Bitcoin core contributor So I'm very grateful to Matt for that and it was great talking to him in the studio

SPEAKER_01: So today we actually had a slew of things we were going to talk to him about we gave him eight different options to look Over and he chose four and then we only talked about two So we're going to talk a little bit about compact blocks and the fiber network that he set up

SPEAKER_03: Very cool.

SPEAKER_01: Enjoy. Welcome, Matt. Hi. Hi, Matt. So today we're gonna do a little bit of this is your life, Bitcoin. And- I'm not dead yet. And so we've dug up some, I mean, you have a lot of contributions over the years, and so there's lots to talk about, but we'll start with three. Maybe let's start with compact blocks. So tell us a little bit about what compact blocks are, and then we can dive a little bit deeper.

SPEAKER_02: you

SPEAKER_03: Bye.

SPEAKER_02: starting getting right into it. Yeah, so compact blocks was kind of the culmination of a number of at the time had been worked on a series of projects related to mining block propagation. So it was to some extent motivated. The genesis of that work was motivated a little bit by the selfish mining thinking and the concerns around if a larger pool can get a material advantage in block propagation versus smaller pools, this may give them a super linear reward. So the design of Bitcoin mining is such that if you have X amount of hash power, you should get X percentage of the reward, and that should be completely linear. So if you have 2X, it should be exactly 2X the reward, and there should be no kind of increase. But certainly, if you have poor block propagation and a very large pool, this is not the case. And we've seen this with a number of various altcoins that have kind of turned the dial up really high on the amount of work that miners have to do to validate blocks or the amount of the size of blocks. And we've seen, in fact, where larger pools will make materially more reward than smaller pools per hash rate.

SPEAKER_01: You

SPEAKER_00: Yeah. Can we go into that just a little bit more so when you say super linear Why is that important why do we care that the proportion of reward that a minor gets is equal to the proportion of its high rate?

SPEAKER_02: Right, yeah, I mean, we want to make sure absolutely that there's no incentive for miners to join a larger pool. So pools provide an important service, they smooth out the reward for their users, but it should not be the case that users want to join a larger pool than necessary because if they do, then we're just going to end up with one big pool or two pools and then Bitcoin is super centralized. As long as there's not a strong incentive for that to happen, then it might happen due to market forces, but that can also still be temporary and somebody else can spin up a new pool if they're a little less concerned with a little bit of variance and the market can take care of that problem a little better if there's no kind of much, much, you get paid more if you're on a larger pool.

SPEAKER_00: Great. Okay. And so how does block propagation speed play into this? So if we had, for example, well, in Bitcoin, we have 10 minute blocks. If we had 15 second blocks or very large blocks, how would that affect this proportionality of reward?

SPEAKER_02: Right, so if a pool, you know, if you have blocks coming out very quickly, if a pool has more, if they kind of see the blocks faster because they mined them, or if the time it takes for them to download the blocks from other pools or validate the blocks that make sure they're valid before they can start mining on them, if that takes a while, that's wasted time that their competition might not necessarily be wasting. Right, so if you mined the block, you know it's valid and you can immediately start mining on top of it. If you didn't mine the block and you have to download it from someone, that time that it takes is time that your competition is mining and you're not, or you're mining something that's not going to give you value. And in fact, we saw this for a very long time on, for example, Ethereum, where larger pools were making a good chunk more money. And so if you were not on one of the largest pools, you were wasting money, you were wasting your hashrate and were not making as much as your competition.

SPEAKER_01: Can you tell us just in sort of human terms what kind of propagation we're talking about? What do you see? Or what have you seen in the past?

SPEAKER_02: So I don't think we've ever really had much of a problem with this in Bitcoin. In large part because, you know, the network has grown slowly while we've been able to kind of stay ahead of it. You know, if we were to take Bitcoin core circa 2011, then and threw it at the network today, you'd see massive issues here, right? It would take 30 seconds to verify a block, and that's a good chunk of the percentage of a block every 10 minutes.

SPEAKER_00: So let's let's just talk about those figures a little bit a block should come out every 600 seconds So if it takes 30 seconds to get from the miner to the other miners, that is 5% So 5% of the time the other miners are doing useless work They're not doing work on the the latest tip and so there'll be 5% they'll get 5% less revenue and that is material because That doesn't mean 5% less profit. It means no profit or loss

SPEAKER_02: Right? Yeah, yeah, absolutely. And the yeah, because mining is a super competitive market, if you're, you know, you talk about some of these pools are charging a few percent fee, you know, if they're out half a percent on revenue, or point one percent on revenue, that might actually be a really significant part of their profit. A little bit less so for miners, but also there, you're looking at super competitive market where your profit margins not going to be that that is going to be pretty thin. So not a large percentage in terms of like wasted hash rate is going to turn into a fairly large percentage of lost profit.

SPEAKER_01: As block propagation starts to get larger, you also have not just people working on blocks that that that's wasted work, but then you're sort of confusing the network by propagating blocks if you found a different nonce or whatever the case may be. Is that the case? Is that is that a right way to think about it? You'd see more.

SPEAKER_02: You'd see more orphans, hopefully the network would not have too many problems, a lot of people do accept one confirmation transactions right now, that's maybe not an ideal thing to do. So people who are doing that might see more issues, but for the most part, I think people are aware that if you're accepting a one confirmation transaction and it's for substantial value, you're taking on some risk. So hopefully it wouldn't kind of confuse the network too much, but it would be wasted hashrate, which is also wasted security for the network, because you know, hashrate is providing security and anti double spend protection, you know, anti reorg protection. And if we have 5% orphans, then that's 5% less security that an attacker doesn't have to fight against.

SPEAKER_00: I'm just going to make a small pedants note here that Matt used the word often block. I prefer stale block. I think often is confused with when you have a block that doesn't connect to the main chain. But moving on. Captain Net. Yeah, just wanted to net that one.

SPEAKER_02: So that was kind of a lot of the motivation for a lot of this work. So there were kind of two directions that I ended up going with it. First is, you know, you're never going to beat a carefully laid out network topology in terms of relay. So if you're talking about a selfish mining model where any advantage, even if it's one millisecond is a complete advantage, this is a little different than the propagation model we were just talking about, but any advantage. If you're in that model, then you need a very carefully laid out topology. And so, you know, I spent a lot of time building relay networks that are, you know, centralized but carefully laid out to be optimal for block propagation and then kind of open them up so that anyone can use them so that hopefully smaller pools can use those, you know, because larger pools do have these networks. They built them themselves. They use them to propagate their own blocks. So this is kind of an alternative to say, if you're a smaller pool and you don't want to set these kinds of things up, you don't know how, you don't have the time to invest, you don't have the money to invest, you can just use this and it's mostly as good and you should just use this.

SPEAKER_01: I was going to say before we go too far, I just want to define selfish mindings for folks that don't quite understand what that is.

SPEAKER_02: I want to take that so selfish mining is a is a attack model and it kind of spawned a number of further research so surface mining was an urgent paper in what 2012-2013 about bitcoin mining strategies so if you're a miner do you you know when you find a block what do you do with it you immediately broadcast it and tell everyone do you sit on it and try to mine something on top of it and then tell people what happens when some other miner finds a block do you immediately mine on it so there's there's actually a lot of you know there's kind of the normal strategy if you find a block you tell everyone there's the normal strategy if someone tells you about a block you immediately start mining on it but there's a lot of academic research around how do you actually do that is that actually the most profitable thing you can do and it turns out that you know if you're a smaller miner and other miners are using this normal strategy and there's a block reward yeah you almost certainly want to just do that if you are if there's no block reward and we're relying on the fee market things look a little hairier or if you are a very substantial miner or if you have a very substantial network advantage in terms of you can propagate blocks faster than everybody else and you can see when others find blocks before they've told everyone about those blocks then there are other strategies that might be more optimal

SPEAKER_00: and notably other strategies that don't require 51%. You could use selfish mining if you have, for example, 40% of the hash power and it might end up being more profitable than being a, quite so honest, miner extending the longest chain.

SPEAKER_02: Yeah, it's a weird attack in the sense that it gives you super linear profit. It doesn't allow you to arbitrarily double spend. It doesn't allow you to arbitrarily censor people's transactions on the chain, but it does give you super linear profit and potentially allows you to force some of your competition out of business, which of course would eventually allow you to become a 51% attacker.

SPEAKER_01: So back to the original discussion. All right, so

SPEAKER_02: Right, so one direction in solving network propagation is kind of coming to the understanding that no peer-to-peer network is going to beat a carefully laid out topology and trying to provide competition for larger pools who have their own carefully laid out topology. And then the other direction in it, which is kind of compact blocks, is just working on making sure that the peer-to-peer network is as fast as we can make it. So it has constraints in that the connections are random and you're never really kind of gonna be able to find the absolute lowest latency path between any two peers in a network that is designed to be as robust as possible. You know, the peer-to-peer networks is not designed to be absolutely blazing fast. It's designed to make sure that if there is a block, everybody can see it and everybody comes to consensus on what the current chain is. So with that in mind, you know, we should make it as fast as we can, but there are limits. So compact blocks is one part of it. So compact blocks is how do we make sure that a block going over the network is smaller so that we can propagate it faster, right? Just pure network bandwidth. You know, there's only so many bytes you can shove down a small pipe at once. And if a block is one megabyte, that is non-trivial in terms of, you know, if your goal is to send it over the wire in under a second or a hundred milliseconds or 10 milliseconds, one megabyte is pretty non-trivial, especially if you're talking about any kind of packet loss crossing the great firewall, you're looking at a lot of packet loss, you know, in and out of China, or if you're on like kind of a residential connection or something like that, again, it starts to be a kind of non-trivial amount of data. So, you know, compact blocks is saying, well, look, here's this block. It's got a bunch of transactions in it. Chances are we've already seen all of those transactions. They've been in our mempool for a while. That's why the miner included them. Why are we sending these things again? And so all you're doing essentially is you're saying, I'm going to take all these transactions. I'm going to look at what was already in my mempool. I'm just going to send you, well, I'm going to send you a list of the transactions in the block. You're going to look at what's in your mempool. You're going to say, oh, I've got most of these. Oh, here's this one I'm missing. And then you're going to ask for that one and then you're going to receive it. And now you've got the block. This also makes a really big difference. I don't know. I assume most of the listeners were around in the early 2000s or late 90s and were like alive, just alive, alive and on the internet and, you know, tried to use torrents and would not irregularly have someone screaming from down the hall, turn off your damn torrents because the internet's not working because you're eating all the upload bandwidth and there's buffer load issues. But Bitcoin actually had that problem as well, right? When a new block came out, if you were running a full node that was publicly accessible, chances are your internet fell over because all of a sudden, when a new block comes out, you're uploading it to 20 people. And in the absence of good queuing strategies, uploading something to 20 people will make your internet fall over. And so compact blocks also, again, because it smooths out, it removes these peaks in network bandwidth, kind of smooth that out, it largely solved that issue for a lot of people.

SPEAKER_03: is-

SPEAKER_00: So, just recapping, prior to Compact Blocks, and this was back in 2015, 2016 that this was implemented, prior to that, I'm running a node on the Bitcoin network, I have peers that I connect to, I receive transactions outside of blocks, unconfirmed transactions which go into my mempool, and then when I receive a block, most, if not all, of the transactions in that block are transactions I've already seen, so I'm downloading the same data at least twice. And then after Compact Blocks, you've kind of pre-cached all of those transactions that you've seen already, you don't need to download them again, you just download the header and some short identifiers for the transactions. What kind of difference does that make? So, in 2016, a full block would have been one megabyte, now it's maybe two megabytes or a little bit larger. And for a Compact Block, what size do we get?

SPEAKER_02: Uh, it's like, you know, uh, maybe 2000 transactions times six bytes per transaction. Uh, so maybe 10 kilobytes, maybe 15. Okay. Um, now, uh, any transactions that you're missing cause a round trip. So, uh, if you know more often than not, you're not missing any transactions, but, uh, any transactions that you are missing, you're going to have to just request those. So you have to send those again. But usually it's kind of just the initial sketch. So it's just, uh, the block header and then, uh, six bytes per transaction. That six bytes is just, uh, the essentially the transaction hash, but the transaction hash with some extra data, uh, shoved in just to make things unique. Um, and yeah, I mean, it's essentially just always that and that's all you need.

SPEAKER_00: we've reduced a two megabyte block to around 18k which is a pretty nice win.

SPEAKER_02: Yeah, and it makes a real difference for either people who have buffer load issues on their upload link or people who are kind of worried about upload and downloading blocks from users on residential connections. It makes a pretty good difference.

SPEAKER_01: This is a technical podcast, so we don't want to go too deep in the philosophy, but in terms of thinking about consumer-grade internet connections and the importance of enabling normal users in their homes to be able to use Bitcoin, where do you draw the line of performance for the network and performance for the individual user?

SPEAKER_02: Yeah, I mean, it kind of gets back to the like, what is the goal of the peer-to-peer network? And in my mind, the goal of the peer-to-peer network pretty clearly is censorship resistant access, censorship resistant consensus system to enable this network of nodes, which, you know, users decide to run on wherever they are, whether it's an LTE modem or a 10 gig fiber line, uh, to come to consensus, right? So these nodes, whatever they are, need to come to consensus. It needs to be robust. It needs to not fall over if half the nodes are malicious or 90% of the nodes are malicious. Um, all these kinds of like, that's the goal. The goal is not let's make this as like screaming fast as possible. Let's like optimize who you connect to for the lowest latency. Uh, because it, once you start doing that, it becomes very hard to keep that robustness property. You know, if you only connect to nodes with the latency, well, you're only connected to nodes near you and an attacker just has to spin up a bunch of nodes near you. And all of a sudden that's the only thing you're connected to. Um, so there are a lot of things that you can do to

SPEAKER_00: kind of conflicting goals. And also in that model, you get a lot of very closely connected subgraphs, and it would be easier for an attacker to partition the network.

SPEAKER_02: Right. Right. Yeah. So, you know, these are kind of conflicting goals. And, you know, if Bitcoin should strive to be robust in my mind. And so that's kind of where this divergence of, okay, here's a peer-to-peer network that's super robust, and we make it as fast as possible and easy to use. And, you know, it's not going to cause buffer bloat problems in your home network. But also, here's some other more centralized things that are as fast as we can make them. So that, you know, uh, you know, there's better competition across larger and smaller. Something like five.

SPEAKER_01: Cyber, for instance. Built-in transition. You love that transition? Oh, come on.

SPEAKER_00: what is a fiber? And if you wanted to write that down in the English language, what letters would you use in each order?

SPEAKER_02: in the british language or the english language choose old british i get it all right

SPEAKER_01: Mm-hmm

SPEAKER_00: Thanks for watching! All right, what is fiber?

SPEAKER_02: All right, so it's the the background is fast internet Bitcoin relay engine. So it the in fact compact blocks was built as a part of fiber and then spun out and included in the Bitcoin peer-to-peer network, not the other way around. But so fiber is the second generation of these kind of centralized but open relay networks that I've built. The first generation was something like compact blocks, but still built on top of standard TCP, still had head of line blocking problems, and fiber largely was intended to solve head of line blocking, right? So if you have a TCP socket, it's modeled after a UNIX socket, you know, if I write bytes into a TCP socket, there's going to be all these packets that go over the wire and blah, blah, blah. But it's going to come out to your application on the other end, in the same order that it was written, it's all going to be not going to be any hopefully no corruption, it's just going to be all in order. Well, all in order is great, unless you received packets two through 15, but you missed packet one, and well, now, the application can't receive anything because it has to be in order. So we have to go back and, you know, potentially crush an ocean again, ask the sender, hey, yo, I missed packet one, can you resend packet one? And then we download that and you know, all of a sudden, we've crossed the ocean a few times and now we have the data and that's great. But we're talking about a few megabytes of data, if it's compressed with something like CompactBox, a few kilobytes, sending that through, you know, a one gig line, like you have on most servers is, you know, a few milliseconds, but crossing the ocean is our round trip across the ocean is 80, half way around the globe, 100, 150. So that act of kind of crossing the ocean again to fetch something you're missing is way, way, way worse than just sending the data five times, right? So the initial version of the kind of Bitcoin relay network that I deployed still used TCP, it had even better compression than CompactBox, but required a lot more memory per connection, so it wasn't suitable for Bitcoin peer-to-peer network, but in a centralized network it worked reasonably well, got a lot of blocks down to one or two packets, so hopefully packet loss was less of an issue, but, you know, you still had kind of a very long tail of if you happen to lose a packet during sending, well, your block propagation is going to be pretty slow. So Fiber was kind of a redesign saying, okay, the biggest problem is we don't ever want to have to ask for a lost data. And the obvious solution here is a set of technologies called forward error correction. So forward error correction, if you are familiar with Shamir's secret sharing, it's actually the same, the simple version of forward error correction is exactly the same math as Shamir's secret sharing, so you can picture Shamir's secret sharing, right? You have this key that you split across 10 shards, but you only need five to reconstruct it. You can imagine the exact same thing, I've got this block, I've split it into, or I've got, you know, maybe one packet from within a block, I've split it into three shards, but you only need one to reconstruct it. Now I can send all three across the wire, and if I lose one or two, that's fine, I still receive the data on the other end without having to go and ask for it again.

SPEAKER_01: and I'll see you in the next one.

SPEAKER_03: Thanks for watching!

SPEAKER_00: OK, well, in that example, you're just sending the data three times, right? Right. We use, or error correction is used in many places. Like, if you have a CD with data on, it's not just one copy of that data. There's duplicates, and you just recombine them. And if part of that CD gets scratched, you can still read the data from it. So it's used in a lot of places, right?

SPEAKER_02: Right, and you can, and the math can get much more fancy, right? So you can send 1.1 times the data and miss 10% of packets, and that's fine, and it doesn't matter, you know, you're not just resending 10% of packets and hoping that the packet that you lost was one of the ones you resent, you can actually, you can imagine a naive version, or a simple version, if you just want one extra packet, you just XOR all the data together, and then if you lost one packet, well, that last packet is going to be all the other ones XORed together. So this can scale up, obviously there's math that gets very complicated very quickly, but you can do simple extra data sending. Now, Fiber did not, in fact, implement any of this math, I am not competent enough in my linear algebra skills to sit down and figure out high-performance forward error correction libraries, I used some external ones that are actually a very high quality, and then built a custom protocol based on essentially compact blocks, but with some additional data to make it very, very efficient to actually send Bitcoin blocks over the wire using your local mempool as an extra piece of data. So Fiber, essentially, you can imagine it's sending first the compact block header with some additional forward error correction, and then the receiving end, if they aren't missing any transactions from the compact block, they're done. They don't even have to receive any transaction data, they've downloaded this compact block with forward error correction so that even with some packet loss, they've still got it without having to ask for it again, great, and then they've got the block. Now, that said, again, because our real goal here, the top line goal is don't ever have to go ask for data that you missed. If you're missing a transaction, you don't want to have to ask for it. So Fiber not only sends the compact block with forward error correction, it also sends all the transaction data with forward error correction. And so what you do is you've received this compact block header.

SPEAKER_01: Mm.

SPEAKER_02: you find any transactions that you do have, and you start initializing your forward error correction data with those transactions, as if you'd received packets. But of course, you have received nothing. You just already have them in your mempool. And then, as you receive additional packets with a forward error correction, you can fill in the transactions that you are missing. So in fact, the sender doesn't need to know which transactions you are going to be missing. It's all just forward error correction across the transactions in the block. And if you have most of them, then you only need a few packets, but it doesn't matter which ones you are missing. So you just need a few packets, and then suddenly the forward error correction will spit out the full block data, and now you've got the block. And it works pretty well. So if you just need the compact block header, usually you'll end up receiving the block within one to three milliseconds plus the speed of light. So it does take 20, 30, 40, 50 milliseconds depending on which ocean you're crossing as to how long the data takes to get there. But one, two, three milliseconds plus the speed of light, if you need additional transaction data, the forward error correction does take a little bit of CPU time, but you're still talking 789 milliseconds in addition to the speed of light.

SPEAKER_00: Wow. That's really cool. And that data is sent using UDP.

SPEAKER_02: Yeah, so that's all UDP because, again, it doesn't exhibit this head-of-line blocking issue, and so we can just process those packets as they come in as individual.

SPEAKER_00: packets. So very quickly for the listeners who aren't network nerds, what's the difference between TCP and UDP in 10 seconds or 20 seconds?

SPEAKER_02: So yeah, UDP is just... I have a packet, I send it across the network, hopefully it makes it, and I receive packets. TCP is built on the same basic packet principle, but it does all of the fancy stuff for you to give you a nice stream abstraction. So it will keep track of which packets it's missing, it'll re-request those, it'll re-send packets that didn't make it to the other end, and then at the end you get just a nice stream of bytes that are in order, and you don't have to worry about this whole packet thing and like, lossy, lost packets and all that nonsense.

SPEAKER_00: Right. So from the application's standpoint, it's reliable. Whereas UDP, anything goes, you might drop packets. But because you have forward error correction in this protocol, it's okay to drop packets occasionally. Right.

SPEAKER_01: Yeah, that's really cool. And actually I think we're going to wrap for today because we've sort of covered two things that go very well together in Compact Blocks and Fiber. You've already promised that you're going to come on and talk more. So can't wait to explore more of your projects further. Thanks for coming on. Thank you, thank you.

SPEAKER_02: Thanks for coming on. Thanks. Absolutely.

SPEAKER_00: Thanks so much.

SPEAKER_01: Thanks. Did you enjoy that as much as I did, John?

SPEAKER_00: Yeah, that's great.

SPEAKER_01: That's all fascinating. Yeah, I think the part that I enjoyed the most was sort of thinking about to push something forward or to be innovative in this space, it just sort of feels like a game of context and Matt's been at this for nine years and can hold it all in his head. I really enjoy these kinds of interviews because he has so much intuition about these problems and has sort of the wherewithal also to reach outside the Bitcoin project and think about how other people solve these problems and sort of piece it all together. It's just cool to hear smart people coming up with novel things.

SPEAKER_00: Yeah, it's fascinating how Fiber takes together concepts from networking and from error correction and then changes in the application layer and then all of the physical aspects of having data centers around the world and Fiber under the oceans and it's just a really impressive project to bring all those things together to bear on a problem in Bitcoin. So at the start of the episode, I mentioned that I met Matt through the residency at Chain Code in 2016. That was a great program and transformational for me in my journey in Bitcoin. And I'm pleased to say we're running the fifth residency at Chain Code this summer. In early June, we're running a residency on Bitcoin protocol development and lightning protocol development. And if you're interested in those things, you should definitely check it out.

