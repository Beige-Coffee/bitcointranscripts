---
title: Chaincode Decoded- The UTXO Set - Episode 5
transcript_by: Whisper AI & PyAnnote
categories: ['podcast']
tag: ['Ultraprune episode 1', 'Assume UTXO episode 4', 'John talks about latency comparisons on a human scale. (Note: He incorrectly says that 1 second for RAM access equates to "months or years" for disk access. Actually 4 minutes for RAM access equates to 1-9 months for disk access.)', 'utreexo']
---

Chaincode Labs podcast: Chaincode Decoded: The UTXO Set - Episode 5

SPEAKER_01: back in time to version 0.1 all that was stored was the blockchain and I think a marker saying whether that coin was spent or not I mean that's okay for your first version but it doesn't really scale and it's bad performance because every time you want to access a coin you need to read it from disk

SPEAKER_00: Welcome back to the chain code podcast. This episode is going to be a little bit different. We're going to do something. It's just, there's no, there's no guests. It's just John and I talking. Hi, Jonas. Hey, John. This was suggested to us by one of our listeners and credit goes to a media on this. She suggested that we rewind a little bit and talk about some of the technical concepts that we're discussing with our guests. So we're going to call this chain code decoded. What do you think about that? John? I think it's a great name. I love it. We've been desperately looking for an opportunity.

SPEAKER_01: Thanks for watching! desperate. Welcome to the chain code decoded podcast. So what are we going to talk about today, John? Well, we thought it'd be interesting to go back and discuss something that we talked to two of our guests about. In episode one, we had Sipa talking about ultra prune, which was a PR that he implemented in 2012. And in episode four, we talked to James O'Byrne about assume UTXO, which is a an ongoing project that he's working on right now. And in both of those episodes, we discussed something that we call the UTXO set. So today we're going to go back and talk about that some more and give a bit more context on what that is.

SPEAKER_00: Very good. So maybe start off, what is the UTXO set?

SPEAKER_01: The UTXO set is Bitcoin. It is what Bitcoin is, and it is what the consensus algorithm behind Bitcoin is designed to allow us to all reach a shared state on what the UTXO set is. So if I have a wallet in Bitcoin, I don't have an account, there's no such thing as accounts on the network level, on the protocol level. I just have a bunch of transaction outputs, and we call those my coins, and when I want to create a transaction, I spend some of my coins, and I create new coins. So Bitcoin is this set of coins, the set of transaction outputs, and every transaction can be seen as a patch on that set. It removes some items and adds new items. It removes the outputs that are spent and adds some new outputs from those new transactions. And if we think about a block, a block is an aggregate of transactions, and it can be thought of as the union of all of those patches. So a block removes some UTXOs from the set and adds new UTXOs that get created in that block. And if we think about the blockchain, that is simply a sequence of these blocks, each of which removes some UTXOs and adds new UTXOs. So the blockchain is this append-only log with proofs attached, and if I give you that log and you replay it, each of those blocks in turn will amend that set, and at the end, you should arrive at the same result that I arrive at, and that is what we call consensus. We've reached the same result.

SPEAKER_00: Cool, so tell me a little bit about the difference between sort of the abstract concept of the UTXO set and maybe the more concrete implementation in Bitcoin Core or in Bitcoin.

SPEAKER_01: Yeah. So what I've been talking about so far as a, a UTXO set is a very abstract idea. Um, it, it exists as part of the protocol is something we can talk about and think about. Um, but let's, let's kind of move from that to how it's implemented, um, in software and what the data structures are and what's actually going on in your Bitcoin core node to turn that kind of abstract idea into something that's more real and concrete. In Bitcoin core, as it stands today in 0.19 and 0.20, we have what's called a coins database. Um, so all of these coins are stored either in memory or on disk in this large database that is indexed by what we call the out point. And that out point consists of the transaction ID and the index of the transaction output that the coin is. If we go back in time to earlier versions of Bitcoin, um, let's go right back to the beginning to version 0.1, there was no concrete implementation of the UTXO set. It was an abstract idea that people could talk about later, but actually in software, all that was stored was the blockchain and an index from the transaction ID into that blockchain together with, I think, a marker saying whether that coin was spent or not. Um, that's, I mean, that's okay for your first version, but it doesn't really scale and it's bad performance because every time you want to access a coin, you need to read it from disk. So in 0.8 in 2012, Peter Wooller implemented ultra prune and go back to episode one, if you want to hear about that. Um, and then in 0.15, uh, which would have been around 2016, the format of that database was changed. It was previously keyed on just a transaction ID and then each of the outputs was kind of a sub-entry below that to being keyed by the output itself.

SPEAKER_00: So, like, how big is this data structure at this point, and I guess in what cases do we need to access it?

SPEAKER_01: Data structure at this point, I believe, is on the order of four gigabytes, plus or minus a gigabyte, I think. And so for a large machine, you can easily store all of that in memory. But for a less powered machine, you're not going to be able to get all of that in RAM.

SPEAKER_00: And maybe before you go too much further, like what are the advantages for maybe people who are on the cusp of understanding what you're talking about? What are the advantages of keeping in memory when you're putting it on disk?

SPEAKER_01: performance yeah predominantly so accessing data from disk either to write it to disk or to read it from disk is many many times slower than accessing memory RAM so it might be the order of like a hundred thousand or something like that yeah so if it's you know if you scale up the times and it's like a second for memory then it would be months or years so it's just much much quicker to keep stuff keep stuff in memory when you can but obviously memory is limited and so if this data set becomes too big for your machines memory you need some way of what we call flushing that to disk and so we have most of it stored on disk and then above that we have what's called a cache for items that we think are going to be accessed more frequently and that way we can get good performance and yet you know we can still store the entire data set without running out of memory

SPEAKER_00: Cool. So, in what cases do we need to access it?

SPEAKER_01: We access this whenever we try and spend a transaction. So if a transaction comes in, that transaction contains inputs, which are the coins that are being spent, and it produces new outputs. And so to verify that transaction as a full node, I need to first of all make sure that those coins exist, that it's trying to spend, so it's not just trying to make money out of thin air, and also that it fulfills the spending conditions of those coins. And those spending conditions are usually produce a signature for the public key, which is associated with this output. So that's what the UTXO set does. It allows a full node to verify first of all the existence, and then verify the spending conditions are met when that coin tries to be spent.

SPEAKER_00: Got it. So there's got to be you know, we're talking about memory. We're talking about flushing into disk There's got to have to have to be some sort of cache layer as well Like can't tell me is there is there is that exist and if so, are there different layers to it?

SPEAKER_01: Yeah, exactly. There are many layers to it. So at the bottom, you have your disk and when you shut down and start up, that's where everything lives because the memory does not persist between running Bitcoin Core and shutting it down and starting up. So at the end, when you shut down your Bitcoin D-node, it saves everything to disk. At the start, you load it up and you have all of the coins on disk. And then you want to access those coins and keep them in memory where you can. And as you run Bitcoin and progress through the blockchain, you'll access coins to spend them, but you'll create new coins as they're being created in transactions. And those will be stored in a cache. And that cache actually is more of a, it's generally more of a write buffer than a read cache. Because generally, we only read coins once, because coins only get spent once. So you don't get much benefit from a read cache where you're reading the same thing many times, but you do get benefit if you say, create a new coin, keep it in your, your cache, and then spend it before you need to flush it to disk. That's a, that's a big win, especially in initial sync. So we have the, we have the disk. That's a base layer. Above that, we have our coins cache. And then in various places, we might have a cache above that, the second layer. So for example, the mempool is a cache above that. Or when we're connecting a block, we'll have a cache above that. And if that block is successfully connected, we'll flush that higher level cache down to the lower level cache. And if it doesn't succeed in being connected, we just throw away that higher level cache. So those changes don't propagate.

SPEAKER_00: Thanks for watching! So listeners might have heard of the DB cache parameter. What's that? And why does that affect what's going on during initial sync? Also known as initial block download.

SPEAKER_01: What's that? So DB cache is a parameter that controls the size of that that first lower level cache that I talked about earlier and obviously the bigger that is, the less frequently you need to flush out that cache. The default setting for DB cache is 300 megabytes. So that means when you turn Bitcoin on for the first time and you start downloading blocks, you'll be creating these new coins from the blocks will be adding new coins to your UTXO set stored in your coins cache. And when that reaches 300 megabytes, the cache is full up and you need to flush the disk. And that is pretty slow. It's a little bit disruptive to initial sync because everything pauses whilst you write everything to disk. And then subsequently, everything is cleared from that cache. So when you come to spend those coins in a later block, it needs to be read from disk again. And so you lose both on having to write and having to read. The larger that DB cache is, the less frequently you need to do that flush to disk. So if you have a slow block download and you have memory to spare, try bumping up that DB cache to a higher number than 300. Instantly, I prefer the term initial sync to initial block download because there's a lot more going on during that process and downloading blocks. The vast majority of work is checking signatures and doing these flushes to disk and reads from disk. So I think initial sync kind of captures that whole process a bit better.

SPEAKER_00: Got it. So this set seems to change a lot and we're talking about, obviously it's very important and everybody has to keep track of it. So are there, this sounds like a problem for accumulators or something like that. Are there sort of different ways to keep track of the set or is anyone working on something like that?

SPEAKER_01: Yeah, absolutely. There have been a lot of proposals, a lot of theoretic ideas about what you can do instead of just keeping this very large set of data. If we go back to what I said the UTXO set was used for, first was existence of a coin in that set, and second was to know what the conditions of spend of that coin are. So we can potentially use interesting cryptographic constructions where we don't actually need to store that data ourselves. We simply store some artifact, let's call it an accumulator, where if someone wants to spend a coin in a transaction, they provide some succinct proof that that coin is a member of the set. And if they give you that proof, and you have this artifact, this accumulator thing, you know for sure that that coin existed. So it's an interesting area of research, and there are lots of variations on how you might do this. The main downsides, well there are many downsides, but areas for research are the performance of these accumulators or accumulator-like structures, and whether doing this changes the trust model, this would obviously be very disruptive for the peer-to-peer layer because you're changing the traffic and what you need to receive when validating a block or a transaction. So right now it's more kind of an area of scientific research, but in the future we might see potentially Bitcoin moving to a model where instead of having to store this very large data set, you simply store a much smaller set. And that set could be some kind of accumulator like a traditional RSA accumulator. It could be some kind of Merkle construct, like a Merkle tree or mountain range. And an interesting proposal here comes from Tajdraya in the form of UTRIXO. So look up that paper if you're interested in this.

SPEAKER_00: So the way you're talking about this, the UTXO just continues to grow. Is that the case? Are there ways to consolidate it? Do we want it big? Do we want it small? Sort of what's the future of the UTXO set?

SPEAKER_01: Well, smaller the better, because this is a data set, a structure that every four node in the network needs to store. And even if you run a pruned node, there's no way to prune the UTXO set. You need it if you want to validate all blocks and transactions coming in. So everything else being equal, we'd like it to be small. And unlike the blockchain, which always grows, the UTXO set doesn't necessarily always grow. We've seen we've seen points in the past where the UTXO set has shrunk.

SPEAKER_00: And why, like historically, why would that happen?

SPEAKER_01: Well, during 2017, um, it grew, there were lots of transactions, lots of traffic on the network and fees went up very high, um, and following that in 2008, 2018 fees reduced again, and a lot of actors on the network saw that as an opportunity to do what's called UTXO consolidation where, um, they had, if you like a purse full of very small coins and they took those and combined them into one larger coin, um, and across the network, hundreds of thousands or millions of UTXOs were consolidated in this way.

SPEAKER_00: And so for a company, why would they want to do that?

SPEAKER_01: Well, for a company, it's in their financial interests because if fees go up again in future, the fee that you pay is proportional more or less to the number of UTXOs that you use as inputs to that transaction. So if you can use them all up to consolidate when fees are low, when fees go higher, you will save money because you'll have fewer UTXOs and therefore fees will be low.

SPEAKER_00: But are you trying to clean up like things that are close to dust limit and try to you know if you're thinking of like pennies and like turn them in for $10 bill or are you trying to take all your pennies and turn them to a hundred dollar bill or even larger

SPEAKER_01: Well, it depends on your usage pattern. There are trade-offs in general. Fewer UTXOs are better in terms of cost, but there might be a trade-off in terms of privacy and especially for an exchange, they might want to have many UTXOs in their hot wallets so they have available UTXOs to make withdrawals. So they need some kind of management of their UTXO set, which does not just fully optimize for having one big UTXO. So there are trade-offs. But in general, wallet behavior can have a big impact on what happens to the UTXO set over time and especially default wallet behavior in popular wallets. So Bitcoin Core in, I think around 0.18, I'm guessing, changed the way that it selects UTXOs for inclusion in a transaction from quite a naive model to a more sophisticated model called branch and bound, which would optimize for not creating change outputs. And so over time, you'd expect the number of UTXOs in your wallet to decrease because you're not creating change outputs. And if everyone does that across the network, then the global UTXO set shrinks.

SPEAKER_00: Well that was a great conversation and I guess we want to hear from the listeners as to whether they thought this was useful and whether we should do more of these in the future. Do you want to hear from guests? Do you want to hear from John and I just talking about technical stuff? It's up to you. So we'd love to hear from you. Thanks. Bye bye.

